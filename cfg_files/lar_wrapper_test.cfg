[global]
group = dune
experiment = dune
wrapper = file:///${FIFE_UTILS_DIR}/libexec/fife_wrap
basename = protoduneana_\\\${SAM_PROJECT}_\\\${consumerid}_\\\${CLUSTER}_\\\${PROCESS}
nevents = 50
#numjobs = 10

#[executable]
#name = lar
#arg_1 = -c
#arg_2 = \\\${CONDOR_DIR_INPUT}/grid_pduneana_Prod4_job_g4rw_systs_new.fcl
#arg_3 = --sam-application-family
#arg_4 = protoduneana
#arg_5 = -n
#arg_6 = 50
#arg_7 = --sam-application-version=v09_29_00

#"--sam-application-family=%s" % args.sam_application_family,
#"--sam-application-version=%s" % os.getenv("PROTODUNEANA_VERSION")

[executable]
name = ./lar_wrapper.py 
arg_1 = -c
arg_2 = \\\${CONDOR_DIR_INPUT}/grid_pduneana_Prod4_job_g4rw_systs_new.fcl
arg_3 = --sam-application-family
arg_4 = protoduneana
arg_5 = -n
arg_6 = %(nevents)s
arg_7 = -j
arg_8 = %(basename)s_temp.json
arg_9 = --rootname
arg_10 = %(basename)s.root
arg_11 = --fix_count

#[stage]
#lines_1 = '+FERMIHTC_AutoRelease=True'
#lines_2 = '+FERMIHTC_GraceMemory=1024'
#lines_3 = '+FERMIHTC_GraceLifetime=3600'

[env_pass]
IFDH_DEBUG=1
IFDH_CP_MAXRETRIES=3
OUTPUT_DIR = /pnfs/dune/scratch/users/calcuttj/pduneana_test/mc/
EXTRA_DIR = .

[sam_consumer]
limit = 8

[submit]
G  = %(group)s
OS = SL7
memory = 3000MB
expected-lifetime = 4h
n_files_per_job = 5
dataset = calcuttj_PDSPProd4a_MC_1GeV_reco1_sce_datadriven_v1_first_10 
resource-provides = usage_model=OFFSITE,OPPORTUNISTIC,DEDICATED
f_0 = /pnfs/dune/resilient/users/calcuttj/job/grid_pduneana_Prod4_job_g4rw_systs_new.fcl
f_1 = /pnfs/dune/resilient/users/calcuttj/lar_wrapper.py 
f_2 = /pnfs/dune/resilient/users/calcuttj/mergeMeta.py
c = "has_avx==True"
tar_file_name=/pnfs/dune/resilient/users/calcuttj/pduneana.tar
lines_1 = '+FERMIHTC_AutoRelease=True'
lines_2 = '+FERMIHTC_GraceMemory=2048'
lines_3 = '+FERMIHTC_GraceLifetime=3600'
#lines_2 = '+OriginalMemory=3000'
#lines_4 = '+MaxAllowedMemory=6000'
#lines_5 = 'request_memory=ifthenelse(isUndefined(MemoryUsage),OriginalMemory,MaxAllowedMemory)'
#lines_6 = 'periodic_release=(HoldReasonCode=?=34)&&(request_memory<MaxAllowedMemory)'


[job_output]
addoutput = *root
dest = \\\${OUTPUT_DIR}/\\\${EXTRA_DIR}/\\\${CLUSTER}_\\\${PROCESS}
add_location = True
add_to_dataset = _poms_analysis

[job_output_1]
addoutput = *json
dest = \\\${OUTPUT_DIR}/\\\${EXTRA_DIR}/\\\${CLUSTER}_\\\${PROCESS}


[job_setup]
source_1 = /cvmfs/dune.opensciencegrid.org/products/dune/setup_dune.sh
setup_local = True
ifdh_art = True
#userscript = True
#prescript = env | grep PROTODUNEANA_VERSION
prescript = cp ${CONDOR_DIR_INPUT}/lar_wrapper.py ./
prescript_1 = cp ${CONDOR_DIR_INPUT}/mergeMeta.py ./
prescript_2 = chmod +x lar_wrapper.py
prescript_3 = ls 
