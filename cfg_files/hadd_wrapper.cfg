[global]
group = dune
experiment = dune
wrapper = file:///${FIFE_UTILS_DIR}/libexec/fife_wrap
basename = protoduneana_\\\${SAM_PROJECT}_\\\${consumerid}
listname = root_list.txt
listloc = /pnfs/dune/resilient/users/calcuttj/%(listname)s
split = 10
ntupleprod_version = v00_00_00
output_name = hadd_wrapper_test.root

[executable]
name = hadd_wrapper.py 
arg_1 = -r
arg_2 = \\\${CONDOR_DIR_INPUT}/%(listname)s
arg_3 = --usedb
arg_4 = 1
arg_5 = -o
arg_6 = %(output_name)s 
arg_7 = -N
arg_8 = %(split)s

[stage]
lines_1 '+FERMIHTC_AutoRelease=True'
lines_2 '+FERMIHTC_GraceMemory=1024'
lines_3 '+FERMIHTC_GraceLifetime=3600'

[env_pass]
IFDH_DEBUG=1
IFDH_CP_MAXRETRIES=3
OUTPUT_DIR = /pnfs/dune/scratch/users/calcuttj/pduneana_test/mc/
EXTRA_DIR = .


[submit]
G  = %(group)s
OS = SL7
memory = 3000MB
disk = 30GB
expected-lifetime = 12h
resource-provides = usage_model=OFFSITE,OPPORTUNISTIC,DEDICATED
f_0 = %(listloc)s
c = "has_avx==True"


[job_output]
addoutput = *root
dest = \\\${OUTPUT_DIR}/\\\${EXTRA_DIR}/\\\${CLUSTER}_\\\${PROCESS}

[job_output_1]
addoutput = *json
dest = \\\${OUTPUT_DIR}/\\\${EXTRA_DIR}/\\\${CLUSTER}_\\\${PROCESS}

[job_setup]
source_1 = /cvmfs/dune.opensciencegrid.org/products/dune/setup_dune.sh
setup = NTupleProd -v %(ntupleprod_version)s
